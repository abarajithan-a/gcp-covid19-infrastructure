# Import all the pre-defined templates 
imports:
- path: gcp-pubsub-topic-template.py
- path: gcp-storage-template.py
- path: gcp-bigquery-tables-raw.py

# Build the resources using the respective templates
resources:
# This PubSub topic will be used to trigger a Cloud Function that pulls
# daily CSV data from John Hopkins Github to the Cloud Storage Bucket
- name: abar-ps-topic-covid19-filedate
  type: gcp-pubsub-topic-template.py

# This Cloud Storage Bucket will be used to save the downloaded
# daily Covid19 CSV datafiles from John Hopkins Github repository
- name: abar-gs-covid19-daily-dataset
  type: gcp-storage-template.py
  'properties': {
    'location': 'us-east1',
    'locationType': 'region',
    'storageClass':'STANDARD'
  }

# This is the bigquery dataset to store all the daily ingested raw data for COVID19 project
- name: abar-bq-dataset-covid19-raw
  type: bigquery.v2.dataset
  'properties': {
    'description': "Dataset to store all the daily ingested raw data for COVID19 project",
    'datasetReference': {
      'datasetId': 'abar_bq_dataset_covid19_raw'
    },
    'location': 'us-east1'
  }

# This template builds all table schema definitions in the given bigquery dataset
- name: abar-bq-tables-covid19-raw
  type: gcp-bigquery-tables-raw.py
  'properties': {
    'datasetId': 'abar_bq_dataset_covid19_raw'
  }

# This is the bigquery dataset to store all the datawarehouse and business intelligence
# data models for COVID19 project
- name: abar-bq-dataset-covid19-dw-bi
  type: bigquery.v2.dataset
  'properties': {
    'description': "Dataset to store all EDW and BI data models for COVID19 project",
    'datasetReference': {
      'datasetId': 'abar_bq_dataset_covid19_dw_bi'
    },
    'location': 'us-east1'
  }  


